% !TEX root = SocialVision2014.tex

\subsection{Social network reconstruction: multi-dimensional signal processing on edges}
\label{sec:vis2net}
\vspace{-5pt}

Let $i$ and $j$ be two nodes representing two nodes, and let $y_{ij}(k)$ to be the probability of the $k$-th type of directional relationship $i\rightarrow j$ that takes a value between $-1$ and $+1$. We allow ‘negative probability’ to encode the directional property of social relationships: If the $k$-th type of relationship, for example, refers to ‘parent$\rightarrow$child’, then $y_{ij}(k)=0.3$ means that individual $i$ is the parent of individual $j$ with probability 0.3, and  $y_{ij}(k)=-0.7$ means that individual $i$ is the child of individual $j$ with probability 0.7.  (Undirectional relationship types may be treated as directional where the sign does not matter.) This probability defined on every edge of the social graph may be computed from that defined on the target pairs, because the graph coarsening procedure associates a probability $p_{mi}$, for a particular target $m$ to be condensed in the social node $i$: As a result, given the probability $z_{mn}(k)$ of the $k$-th type of directional relationship between targets $m$ and $n$ computed from the proxeme between them, it is straightforward that $y_{ij}(k)=\int_{mn}p_{mi}p_{nj}z_{mn}(k)dmdn$, as illustrated in Figure~\ref{fig:SP_on_Graph}(b). Note that the semantic image processing tools also provide other individual attributes such as age and gender~\cite{Gender, Age} to the pair $(m,n)$, and the probability of a particular type of relationship, in analogy to $z_{mn}(k)$ but induced by these personal attributes,  may also be computed and transferred to edge $(i,j)$ in a similar manner. 

With these quantities $y_{ij}(k)$ computed, our goal is to compute a set of social adjacency matrices $A(k), k=1,2,…,K$, each of size $N\times N$, where $K$ is the total types of relationships under considerations, $N$ is the number of social members. Each element $A_{ij}(k)$ takes one of the three discrete values -1, 0, or 1, and by definition of the directional relationship, each adjacency matrix is skew-symmetric $A(k)=-A(k)^T$. This requires three-way signal $A_{ij}(k)$ detection over edges of the social graph using ‘observation’ $y_{ij}(k)$.

A set of challenges distinguishes the problem from the majority of conventional studies on signal processing on graphs. First, we require to detect discrete signals defined on edges (1-cells) and this is equivalent to operating in the space of 1-cochains. This differs from the focus of the current studies on graph signal processing or machine learning, which operate on the continuous real or complex signals defined on nodes (0-cochains). Second, the observations $y_{ij}(k)$ are noisy, not only because of imperfect detection and classification or cumulative computing errors, but more significantly because that any two individuals do not necessarily co-occur or interact frequently enough to give rise to adequate proxemes: For some edges, these ``observations" will be unreliable or completely missing. \comment{if few proxemes may be extracted between nodes $i$ and $j$, and it may be even completely missing if no proxeme is available.} Third and finally, the signals across different types of relationships are structurally constrained, just as shown by social network research, where social networks are found to include multiple overlapping and structural communities: Consider the example where the $k_1$-th, $k_2$-th, and $k_3$-th types of relationships refer to ‘mother$\rightarrow$child’, ‘wife$\rightarrow$husband’, and ‘farther$\rightarrow$child’ respectively, and the hypothesis pair $A_{ij}(k_1)=1$ and $A_{il}(k_2)=1$ requires the hypothesis for the 1-cochain $(j,l)$ to be $A_{jl}(k_3)=-1$. Therefore, signals must be collaboratively detected over 1-cells respecting the semantic relationship constraints across the relationship types over higher-order cells. 

To address these challenges, we will develop generic frameworks for collaborative detection of multiple discrete signals defined on edges under unreliable and missing observations\comment{ across multiple relationship types, which are mutually regularized by structural relationship constraints among these types}.  To begin with, we will explore a 2-step approach. In the first step, we will design edge-wise energy minimization models (EEMM) for filtering (denoising) the unreliable directional relationship probability signals of each type and for completing the missing signals over the missing edges. In the second step, we will apply prime-dual transformation to convert structural constraints among subset of 1-cells to independent unary constraints over the 0-cells in the dual cell complex, and this enables us to develop analogies to discrete random-field optimization to solve the discrete decision problem in the dual complex representation.

\boldstart{(1)} We will first develop EEMM for filtering the edge-wise directional probabilities $y_{ij}(k)$ supported by observed salient proxemes to obtain `cleaner’ probabilities $\hat y_{ij}(k)$ over all edges, including those missing co-occurrences in the imagery, as illustrated in Fiure~\ref{fig:SP_on_Graph}(c). The optimal clean signals must satisfy two criteria: First, it must respect the observed signals over the edges supported by observed salient proxemes, preserving `data fidelity’. Second, it must behave as a `low-pass’ filter to preserve the smooth components in the observed signal, treating the `high-frequency’ component as noise incurred for various reasons. As a result, the EEMM minimizes a combination of data fidelity and smoothness
\begin{equation}
\min_{\hat{\mathbf{y}}(k)}\hat{\mathbf{y}}(k)^{T}L_e\hat{\mathbf{y}}(k)+\gamma\sum_{(i,j): y_{ij}(k)~\textup{exists}}\|y_{ij}(k)-\hat y_{ij}(k)\|^2
\end{equation}
where $L_e$ represents the edge Laplacian. It has been proved the edge Laplacian can be rewritten as $L_e=N_{1}N^{*}_{1}+N^{*}_{2}N_{2}$ where $N_{1},N_{2}$ and $N^{*}_{1}, N^{*}_{2}$ are called the boundary operators and co-boundary operators \cite{Grady10}. 

Now that the problem has been transformed to a filter design problem – to determine the boundary operators and co-boundary operators. we may further employ the facts that decompositions $N_{1}N^{*}_{1}=PG_{0}P^{T}G^{-1}_{1}$ and $N_{2}N^{*}_{2}=G_{1}Q^{T}G^{-1}_{2}Q$ exist \cite{SpectralChung,Grady10}, where $P$ and $Q$ are the node-edge, edge-face (2-cell) incidence matrices respectively, and consequently further transform the filter design problem to determine the diagonal metric tensors $G_0$, $G_1$ and $G_2$. As the diagonal element $g_e(i,i)$ encode the ‘weight’’ assigned to the i-th e-cell, one possibility to specifying these weights, is simply to take $G_1=I, G_2=I$, and let $g_0(i,i)$ to be the `weight' on the i-th node as $g_{0}(i,i)=\sum_{j}s(i,j)$ , where $s(i,j)$ are pairwise similarities computed from facial similarities, age/gender attributes, scene types, occurrences, and other kinds of visual clues that may imply the social-affinity between two individuals. In the proposed research, we will explore other ways in accomplishing this filter design, we will also look into different algorithms in performing the optimization, by deriving a corresponding quadratic programming algorithm, or adapting from the backward Euler method \cite{Press:2007}.

\boldstart{(2)} With filtered directional relationship probabilities\comment{ for all individual pairs and all relationship types}, we will in the second step design collaborative detection of multiple discrete signals defined on edges across multiple relationship types regularized by structural relationship constraints, as illustrated by Figure~\ref{fig:SP_on_Graph}(d).  To this end, we may harness Poincare duality property\comment{ for calculus defined on general cell complexes} \cite{SpectralChung,Grady10}, and transform each social graph, considered as a 2-complex, into its dual form. In the dual form, each 2-cell (face) in the primal complex consisting of three individuals becomes a 0-cell (node) in the dual, and the triple-wise structural constraints among the primal nodes are converted to constraints on this single node in the dual. The duality properties between the two forms also provides ways to compute the topologies of the dual complex in terms of the dual boundary operator and dual co-boundary operator, by which one may further derive the Laplacian for the dual complex\cite{SpectralChung,Grady10}.

This dual transformation leads a framework of labeling the dual nodes (i.e., the edge triples in the primal) as one of the triple-wise relationships, each of which is defined by three pairwise relationships. Given a dictionary of all possible triple-wise relationships, labeling a dual node into one of the triple-wise relationships is analogous to encoding it as a \emph{sparse} linear combination of all possible triple-wise relationships in the dictionary, while maintaining consistency between neighboring dual nodes (i.e., primal node triples with overlapping edges). Inspirations may be then drawn from such as sparse coding of image patches while maintaining consistency between overlapping patches \cite{EladPatchDictionary,ZoranSparsepatch}: We will develop sparse coding for labels of cell complexes, apply them to the dual nodes of the social graph, and transform the results back to the primal complex before obtaining the final relationship signal on every edge of the entire social graph.

Based on the findings during the exploration of the 2-step approach, we will continue to look into ways in unifying denoising, edge-completion, and signal detection. The unification will lead to optimization problems that are NP-hard, and we will leverage the expertise of PI Li, who has a history of formulating and solving optimization problems on non-traditional domains \cite{LiPAMI2012}. We will also generalize the approach to signals existing on higher-order cells by directly extending the discussions to higher-order Laplacian, filter design, and primal-dual transformations, and this will provide us the foundation to study larger-size community-wise signals. Last but not least, we will explore ways to scale up the model to accommodate massive number of social members, and we expect to explore frameworks in the spirit of a consensus of distributed local optimizers by PI Zickler and others \cite{ChakrabartiXGZ14}.

\subsection{Closing the Loop: Joint Image Processing and Graph Signal Processing}
\label{sec:closeloop}

A longer term goal of our research is to allow synergistic collaboration between semantic image processing/recognition and social signal detection. We have argued that semantic image processing provides information about an underlying social network, but the converse is also true. As shown by PI Zickler and others~\cite{Stone2008,Stone2010}, social network information can serve as context to improve image-based recognition. We envision a future in which these two processes work together. When uncertainty in an image recognition system leads to low confidence output, the uncertainty propagates to the extracted social cues and therefore to the inferred social network graph. However, by reconstructing and denoising the graph as proposed above, we can improve our estimate of the underlying social network, and then carry this information back to the image data, use the the improved social network as context to correct errors and improve recognition models.




%This dual transformation establishes a random-field model for the dual complex, for which only unary and binary potentials are involved. As a result, discrete optimization procedures, either based on sampling or using linear programming approximation, may be derived for inferring in the dual complex. 


%\subsubsection{Filtering on the edges: relationship propagation incompletely observed  co-occurrence}

%\subsubsection{Detection relationship signals with higher-order relational constraints}

%In addition to analyzing social interactions in videos, we will investigate tools for analyzing social \emph{relationships}, in terms of the social network that embeds the people observed in an image and video collection. As is customary, we consider the social network of $K$ individuals to be an undirected weighted graph $G$, with $K$ nodes and a non-negative weight ($\in [0,1]$) on the edge between each node-pair. Each weight represents the social proximity, or strength of tie, between two people, and the weights are collected in a positive symmetric affinity matrix $A$ of size $K\times K$. As described in Sections~\ref{sec:intro} \& \ref{sec:background}, our goal is to develop network reconstruction methods that are well-suited for vision by simultaneously: 1) modeling the multiple-community structure of social networks; 2) incorporating a variety of noisy sources (i.e., social cues automatically extracted from images and videos of varying quality); and 3) tolerating identity errors and high levels of missing data.

%From detecting, recognizing, and counting occurrences of social proxemes, we will proceed to analyze \emph{social relationships}. As is customary, we consider the social network of $K$ individuals to be an undirected, weighted graph $G$, with $K$ nodes and a non-negative weight ($\in \{0,1\}$) on the edge between each node-pair. Each weight represents the social tie between two people, and the weights are summarized by a positive symmetric affinity matrix $A$ of size $K\times K$. As described previously, our goal is to develop network reconstruction methods that are well-suited for vision by simultaneously: 1) modeling the multiple-community structure of social networks; 2) incorporating noisy proxeme counts from a variety of noisy visual cues; and 3) tolerating uncertain identities and missing links.

%It has commonly been observed that social networks include multiple overlapping communities (e.g.,~\cite{AiroldiBFX08,Kim12}). Computationally, this means that the social distance between nodes is not scalar-valued but depends on the type of roles or memberships being considered (e.g.,~friends vs.~colleagues vs.~family). We refer to these types as different \emph{views} and we represent them by defining $G\triangleq\{A^{(v)}\}_{v=1}^{V}$, where $A^{(v)}$ is the affinity matrix summarizing the ties between every pair of nodes in the $v$th view. For example, if $v\in\{1,2,3\}$ corresponds to friends, family, and workmates, $A^{(1)}(i,j)=1$, $A^{(2)}(i,j)=1$, and $A^{(3)}(i,j)=0$ indicates that Alice ($i$) and Bob ($j$) are not biologically related but are simultaneously close friends and colleagues.

%The multiple views overlap in general, and the effective tie between each node pair depends on which view is be used to assess their relationship.

%In addition to considering multiple views, we will also account for social information coming from multiple distinct cues extracted from visual data, without these cues being associated with peoples' identities with complete certainty. To do this, we consider $S$ \emph{sources} producing socially-informative cues $\vy^s, s=1,2,\cdots,S$, with each $\vy^s(i,j)$ being a multi-dimensional descriptor computed from a distinct socially-informative visual cue related to person $i$ and person $j$. As an example, for a detected, tracked and correctly-identified pair of individuals Alice $(i)$ and Bob $(j)$, a set of sources could include (time-varying in videos): relative positions of the two detections $\vy^1(i,j)$ (or $\vy^1$ for short); relative head poses $\vy^2$; relative body poses $\vy^3$; distribution over interaction categories $\vy^4$ detected and recognized as in Section~\ref{sec:activity}; and scene category $\vy^5$. These cues will not generally be associated uniquely with one pair of individuals because of uncertainties inherent to face recognition and other forms of identity recognition, and this means that each source will generally produce from the same image or video sequence multiple differently-weighted outputs. For example, if we cannot visually distinguish Bob ($j$) from Charlie ($k$) then each source will produce from one video sequence two outputs that satisfy $\vy^s(i,j)=\vy^s(i,k)$.

%Out goal is to infer the set of affinity matrices $\{A^{(v)}\}$ from imagery, using proxeme counts and other visual descriptors as input. In general, there will be multiple proxeme dictionaries that are relevant to the same social network. For example, there may be one based on histograms-of-flow in surveillance videos, another based on head and body pose in higher-fidelity videos, and yet another based on relative body positions in photographs of the same individuals. We index by $u=1,2,\ldots,U$ the available proxeme dictionaries corresponding to different visual cues $u$, and we denote these proxeme dictionaries by $\mathcal{D}^{(u)}$. To robustly exploit the correlations between relationships and noisy proxeme counts,
%consider $S$ types of \emph{cues} yielding socially-informative proxemes $y^s\in\mathcal{D}^{(s)}, s=1,2,\cdots,S$, where $\mathcal{D}^{(s)}$ denotes the dictionary of the $s$th type of proxemes learned from the $s$th type of visual cue. As an example, a set of four types ($S=4$) of cues could include 1) relative positions of the two detections, 2) relative head poses (as used in the classroom videos), 3) relative body poses (as used in the internet images), and 4) short-term interactive actions characterized by flows.
%On the one side, each type of proxeme will not necessarily uniquely correspond to one type of social relationship. On the other side, despite that we learn the proxemes using manual annotations, at runtime we will use existing imperfect tools to compute the visual cue ( \emph{e.g.} \cite{poselet,pose_part} for pose estimation) before classifying it into one of the proxemes, and therefore the recognized proxeme may be erroneous. As a result of both uncertainties, for a detected, tracked and correctly-identified pair of individuals Alice $(i)$ and Bob $(j)$,
%we can learn from training data representations of $P(A^{(v)}(i,j) \mid y^u)$: the probability of a relationship between $i$ and $j$ according to the $v$th relationship view given a detected instance of a proxeme from the $u$th dictionary. An interesting challenge we must address is that identities $i$ and $j$ will also be noisy, since they will be inferred from face recognition and other biometric cues. For example, if we cannot visually distinguish Bob ($j$) from Charlie ($k$) then a single cue $u$ can produce two separate probabilistic signals: $P(A^{(v)}(i,j) \mid y^u)=P(A^{(v)}(i,k) \mid y^u)$.


%\boldstart{Multi-view network regression}. One of our project goals is to establish a unified, data-driven framework for reconstructing multi-view network representations (affinity matrices $A^{(v)}$) from multiple noisy, heterogeneous visual sources. We refer to this problem as multi-source multi-view network estimation, and we will address it using an architecture comprised of $V$ trained \emph{oracles} $\Psi_{v}$ that each provide an estimate of one view $\hat{A}^{(v)}$ from all available vision-based descriptors $\bar{\vy}=[\vy^1,\vy^2, \cdots,\vy^S]$. That is, $\hat{A}^{(v)}=\Psi_{v}(\bar{\vy})$, with $\Psi_{v}$ learned from data according to the following general approach. Given collections of vision-based social cues $\{\bar{\vy}_{n}\}_{n=1}^{N}$ attributed to $N$ different unknown social network graphs, optionally supplemented by additional collections $\{\bar{\vy}_{n}\}_{n=1}^{M}$ attributed to $M$ graphs that are known (i.e., known
%affinity matrices $\{\bar{A}^{(v)}_{m}\}_{m=1}^{M}$, perhaps through non-visual metadata like that described in Section \ref{sec:sys}), we will investigate a family of objectives of the form
%\begin{equation}\label{eq:sensing}
%\{\Psi^{*}_{v}\}=\arg\!\!\!\!\!\!\!\!\min_{\{\Psi_{v}\},\{\hat{A}^{(v)}_l\}_{l=1}^{N+M}}\sum_{m=1}^{M}\mathcal{J}\left(\{\Psi_{v}\}, \{\bar{\vy}_m\}, \{\bar{A}^{(v)}_m\}\right)+\tau\left(\{\hat{A}^{(v)}_m\},\{\hat{A}^{(v)}_n\}\right)+\gamma\left(\{\Psi_{v}\}\right).
% \end{equation}
%The first term $\mathcal{J}$ in this expression is a loss term that gives preference to oracles that agree with the $M$ known graphs. For example, $\mathcal{J}(\{\Psi_{v}\}, \{\bar{\vy}_m\}, \{\bar{A}^{(v)}_m\})=\sum_{v=1}^{V}\|\Psi_{v}(\vy_m)-A^{(v)}_m\|^{2}$ would measure discrepancy from the known graphs in a least-square sense. To prevent over-fitting, the complexity of the oracles is restricted by a regularization term $\gamma()$, whose form depends on the choice of oracles, such as Gaussian process regression \cite{GPbook} or deep learning \cite{DLbook}. We will also explore modifying this regularization term to enforce compatibility between the oracles of different views. Two oracles predicting friendship and adversarialism for the same pair of nodes, for example, should be deemed incompatible. Finally, we include a third term $\tau()$ that regularizes the estimated affinity matrices according to some generic or environment-specific prior knowledge. For these, we will draw inspiration from the many existing statistical graph models~\cite{Goldenberg}.
%
%In this thread of our research, cross-view compatibility and within-view clustering are expected to play essential roles in the multi-view architecture. This distinguishes the proposed work from conventional regression machines, where outputs are mutually independent.


%\boldstart{Multi-cue network estimation}. Assume we have detected proxemes in $N$ images or videos, in which not all pairs of social members are simultaneously observed together. To accommodate these ``missing links'', we define $Q(i,j,n)=1$ to indicate that individuals $i$ and $j$ co-occur in the $n$-th image or video, and $Q(i,j,n)=0$ otherwise. Consequently, $Q(i,j)\triangleq\prod_{n=1}^{N}Q^{(v)}(i,j,n)$ indicates whether the pair $(i, j)$ co-occurs at least once in the entire set.


%A MAP estimate for the affinity $A^{(v)}(i,j)$ between individuals $i$ and $j$ for whom $Q (i,j)=1$ is
%\begin{equation}
%\{A^{(v)}(i,j)\}_{Q(i,j)=1}=\arg\!\!\!\!\!\min_{A^{(v')}(i,j)}\sum_{u=1}^{U}\sum_{n=1}^{N}Q(i,j,n)\log P(A^{(v')}(i,j)|y^u)+\gamma(\{A^{(v')}(i,j)\}),
%\label{netestimate}
%\end{equation}
%where we assume independence among difference visual cues and different images or videos. The regularization term $\gamma()$ whose explicit format depends on the specific social network, is controls two important effects. First, it enforces compatibility between different nodes: friendship between nodes $i$ and $j$ and adversarialism between nodes $j$ and $k$, for example, suggest an adversarial prior between nodes $i$ and $k$ that should be reflected in this regularization. Second, it regularizes the estimated affinity matrices according to other environment-dependent prior knowledge about social networks, for which we will draw inspiration from existing statistical graph models such as~\cite{Goldenberg}. With $\gamma()$ properly defined, the problem (\ref{netestimate}) can be formulated as an optimization on a random field (over graph edges), and it can be tackled using standard random field algorithms. Our work in this direction will leverage the expertise of PI Li, who has a history of formulating and solving optimization problems on non-traditional domains~\cite{LiPAMI2012}.

%The multi-cue network estimation framework is robust to noisy inputs: The evidence about the affinity between a particular pair is aggregated from proxemes using multiple cues and from multiple co-occurrences in the entire image or video set. Therefore, noisy input from a single visual cue and proxeme detection (\emph{e.g.}, noisy pose estimation and noisy pose-pair proxeme) on a single image or video will be overwhelmed by other reliable visual cues and proxemes which are correctly extracted from other images or videos.

%\begin{figure}[t!]
%\begin{center}
%\includegraphics[width=\columnwidth]{featurelearn}
%\end{center}
%\vspace{-0.25in} \caption{\captionsize
%Illustrations for the problem of multi-view network learning from multiple low-level visual clues and the framework of integrated socially-aware computer vision for understanding student netwrok. \label{fig:featurelearn}\afterfigspace}
%\end{figure}






%\boldstart{Reconstructing noise and missing data}. Even with identity recognition aside, the social information extracted from images and videos will be very noisy and incomplete. In many situations, images and videos will be of low quality; agents will exhibit significant pose variations and be occluded; tracking systems will become lost in clutter; and estimates of head pose, body pose, expression, etc. will be plagued by uncertainty. Consequently, missing and noisy links will be especially prevalent in visually-sensed social networks. As part of the proposed activity, we will build on successes in link prediction~\cite{Goldberg,Liben-Nowell,TaskarWAK03} and network completion~\cite{Clauset,Guimera,HannekeX09,KimL11}, by developing reconstruction tools that are better suited to highly-noisy and multi-view visually-sensed social networks.

%\boldstart{Reconstructing missing links}. We have introduced a framework (\ref{netestimate}) to estimate the multi-view affinities between the pairs who co-occur at least once, but we must also develop tools for reasoning about members that do not co-occur and are missing links in the network. Meanwhile, due to other potential factors unaccounted in (\ref{netestimate}), estimated affinities may remain noisy.  As part of the proposed activity, we will build on successes in link prediction~\cite{Goldberg,Liben-Nowell,TaskarWAK03} and network completion~\cite{Clauset,Guimera,HannekeX09,KimL11}, by developing reconstruction tools that are better suited to multi-view social networks with highly noisy and missing links.

%To accommodate missing data, we will modify our representation for a social network graph of $K$ nodes by including a visibility matrix for each view. That is, $G\triangleq\{A^{(v)}, Q^{(v)}\} v=1,2,\cdots,V$, with $A^{(v)}$  the $K\times K$ affinity matrix for view $v$ and $Q^{(v)}$  the corresponding $K\times K$ visibility matrix for that view. If $Q^{(v)}(i,j)=1$, then $A^{(v)}(i,j)$ is the weight describing the tie or closeness between node $i$ and node $j$ estimated from the $v$th view; otherwise if $Q^{(v)}(i,j)=0$ then $A^{(v)}(i,j)$ is a missing number indicating the lack of information in this view. Our objective is to complete the missing links ($Q^{(v)}(i,j)=0$) by estimating the proper weights for these missing links.

%In the case that the views directly correspond to low-level visual cues, we may imagine that the ties between the pairs of members should not vary among different views due to different sensing modalities, and therefore there exist a unique community structure underlying all views. A primary objective in this case, is that how we may discover the community (clustering) effect from this partially observed multi-view network, together with filling the missing links with a proper weight. We refer to this primary task as network reconstruction.

%The key observation is that structure across views can be used to transfer information from one view to the other view, effectively filling holes or filtering noise by borrowing information from other views. This will succeed as long as errors are incoherent across views\comment{, which is a reasonable expectation in practice}. To operationalize this, we let each node $i$ in the graph be uniquely identified with a point $\vx_i$ in a Euclidean space of some dimension, where the distance between each pair of points $(i,j)$ in this space can be interpreted as form of ``view-invariant" dissimilarity between the two nodes. Furthermore, we imagine that every view-specific affinity $A^{(v)}$ can be obtained by a simple global linear transform of the view-invariant Euclidean distance. This model is supported by the following theorem, based on results from multi-dimensional scaling~\cite{CoxMDS} (proof omitted due to space constraints), implying that any graph affinity can be analytically transformed to Euclidean distances between points.

%\begin{quote}
%\textbf{Theorem}. \textit{If $A$ is a symmetric affinity matrix with all zeros on the diagonal and positive numbers everywhere else, there exists a constant $c$ such that $(\frac{1}{A(i,j)}+c)^{\frac{1}{2}}$ is the Euclidean distance between point $i$ (representing node $i$) and point $j$ (representing node $j$) in an Euclidean space, where $c\geq\lambda$, the smallest eigenvalue of $\Lambda=H\Gamma H$, $H=\mathbf{I}-\frac{\mathbf{1}\mathbf{1}^T}{K}$, and $\Gamma(i,j)=-\frac{1}{2A(i,j)}$.} 
%\end{quote}

%The theorem guarantees that each node can be uniquely identified with a point in a Euclidean space, and then one possible way for the Euclidean-embedded nodes $\vx_i$ and the multi-view network $G$ to be related is to let $((\vx_i-\vx_j)^{T}\Sigma^{(v)}(\vx_i-\vx_j)-c^{(v)})^{-1}=A^{(v)}(i,j)+\epsilon^{(v)}_{ij}$, where $\Sigma^{(v)}$ is a symmetric semi-positive definite matrix specific to the $v$th view, and $\epsilon$ is a residual. By doing so, different views are unified, and any network priors or regularizations across views are straightforward to be transferred through the embedded points $\vx_i$. 

%This model we propose differs from existing analyses of embedding~\cite{Hoff01latentspace,Hancocklatent}, multi-view networks \cite{AiroldiBFX08,Kim12}, and network completion~\cite{Clauset,Guimera,HannekeX09,KimL11}, because it uses a latent Euclidean embedding to \emph{simultaneously} consider missing data and multiple views. It promises more effective use of structure that exists across distinct views in a network, something that we view as being very important to the success of vision-based network reconstruction. 

%A unified community clustering effect, as the social network prior, may consequently  be modeled in the Euclidean space as well, for example, via
%\begin{equation}\label{eq:kmeans}
%Z=\arg\min_{D,\hat{Z}}\|X-D\hat{Z}\|^{2}_{2}, \textup{s.t.} \hat{Z}^{T}\mathbf{1}=\mathbf{1},
% \end{equation}
%where $X=[\vx_1,\vx_2,\cdots,\vx_K]$, each column of $D$ represents the center of a cluster, and $Z, \hat{Z}$ are a binary matrices by which we assign a node to a cluster among the communities of interest given by $D$. Upon learning the overall model incorporating the essential components in (\ref{eq:embed})(\ref{eq:kmeans}). It is straightforward to reconstruct the noisy and the missing affinities through transforms of Euclidean distances, and to investigate the underlying community structure invariant of views.



%A longer term goal of our research is to allow synergistic collaboration between visual recognition processes and social reconstructive processes. We have argued that visual recognition provides information about an underlying social network, but the converse is also true. As shown by PI Zickler~\cite{Stone2008,Stone2010} and others, social network information can serve as context to improve recognition. We imagine a future in which these two processes work together. When uncertainty in a face recognition system leads to low confidence in identities, the uncertainty propagates to the extracted social cues $\vy$ and therefore to the inferred social network graph $G$. However, by reconstructing and denoising the multi-view graph as proposed above, we can improve our estimate of the underlying social network, and then carry this information back to the image data, use the the improved social network as context to correct  errors and improve recognition models.
