% !TEX root = SocialVision2014.tex

\subsection{Filtering and detection on the edges and higher-order cells}
\label{sec:vis2net}
\vspace{-5pt}

\subsubsection{Filtering on the edges: relationship propagation incompletely observed  co-occurrence}

\subsubsection{Detection relationship signals with higher-order relational constraints}

%In addition to analyzing social interactions in videos, we will investigate tools for analyzing social \emph{relationships}, in terms of the social network that embeds the people observed in an image and video collection. As is customary, we consider the social network of $K$ individuals to be an undirected weighted graph $G$, with $K$ nodes and a non-negative weight ($\in [0,1]$) on the edge between each node-pair. Each weight represents the social proximity, or strength of tie, between two people, and the weights are collected in a positive symmetric affinity matrix $A$ of size $K\times K$. As described in Sections~\ref{sec:intro} \& \ref{sec:background}, our goal is to develop network reconstruction methods that are well-suited for vision by simultaneously: 1) modeling the multiple-community structure of social networks; 2) incorporating a variety of noisy sources (i.e., social cues automatically extracted from images and videos of varying quality); and 3) tolerating identity errors and high levels of missing data.

From detecting, recognizing, and counting occurrences of social proxemes, we will proceed to analyze \emph{social relationships}. As is customary, we consider the social network of $K$ individuals to be an undirected, weighted graph $G$, with $K$ nodes and a non-negative weight ($\in \{0,1\}$) on the edge between each node-pair. Each weight represents the social tie between two people, and the weights are summarized by a positive symmetric affinity matrix $A$ of size $K\times K$. As described previously, our goal is to develop network reconstruction methods that are well-suited for vision by simultaneously: 1) modeling the multiple-community structure of social networks; 2) incorporating noisy proxeme counts from a variety of noisy visual cues; and 3) tolerating uncertain identities and missing links.

It has commonly been observed that social networks include multiple overlapping communities (e.g.,~\cite{AiroldiBFX08,Kim12}). Computationally, this means that the social distance between nodes is not scalar-valued but depends on the type of roles or memberships being considered (e.g.,~friends vs.~colleagues vs.~family). We refer to these types as different \emph{views} and we represent them by defining $G\triangleq\{A^{(v)}\}_{v=1}^{V}$, where $A^{(v)}$ is the affinity matrix summarizing the ties between every pair of nodes in the $v$th view. For example, if $v\in\{1,2,3\}$ corresponds to friends, family, and workmates, $A^{(1)}(i,j)=1$, $A^{(2)}(i,j)=1$, and $A^{(3)}(i,j)=0$ indicates that Alice ($i$) and Bob ($j$) are not biologically related but are simultaneously close friends and colleagues.

%The multiple views overlap in general, and the effective tie between each node pair depends on which view is be used to assess their relationship.

%In addition to considering multiple views, we will also account for social information coming from multiple distinct cues extracted from visual data, without these cues being associated with peoples' identities with complete certainty. To do this, we consider $S$ \emph{sources} producing socially-informative cues $\vy^s, s=1,2,\cdots,S$, with each $\vy^s(i,j)$ being a multi-dimensional descriptor computed from a distinct socially-informative visual cue related to person $i$ and person $j$. As an example, for a detected, tracked and correctly-identified pair of individuals Alice $(i)$ and Bob $(j)$, a set of sources could include (time-varying in videos): relative positions of the two detections $\vy^1(i,j)$ (or $\vy^1$ for short); relative head poses $\vy^2$; relative body poses $\vy^3$; distribution over interaction categories $\vy^4$ detected and recognized as in Section~\ref{sec:activity}; and scene category $\vy^5$. These cues will not generally be associated uniquely with one pair of individuals because of uncertainties inherent to face recognition and other forms of identity recognition, and this means that each source will generally produce from the same image or video sequence multiple differently-weighted outputs. For example, if we cannot visually distinguish Bob ($j$) from Charlie ($k$) then each source will produce from one video sequence two outputs that satisfy $\vy^s(i,j)=\vy^s(i,k)$.

Out goal is to infer the set of affinity matrices $\{A^{(v)}\}$ from imagery, using proxeme counts and other visual descriptors as input. In general, there will be multiple proxeme dictionaries that are relevant to the same social network. For example, there may be one based on histograms-of-flow in surveillance videos, another based on head and body pose in higher-fidelity videos, and yet another based on relative body positions in photographs of the same individuals. We index by $u=1,2,\ldots,U$ the available proxeme dictionaries corresponding to different visual cues $u$, and we denote these proxeme dictionaries by $\mathcal{D}^{(u)}$. To robustly exploit the correlations between relationships and noisy proxeme counts,
%consider $S$ types of \emph{cues} yielding socially-informative proxemes $y^s\in\mathcal{D}^{(s)}, s=1,2,\cdots,S$, where $\mathcal{D}^{(s)}$ denotes the dictionary of the $s$th type of proxemes learned from the $s$th type of visual cue. As an example, a set of four types ($S=4$) of cues could include 1) relative positions of the two detections, 2) relative head poses (as used in the classroom videos), 3) relative body poses (as used in the internet images), and 4) short-term interactive actions characterized by flows.
%On the one side, each type of proxeme will not necessarily uniquely correspond to one type of social relationship. On the other side, despite that we learn the proxemes using manual annotations, at runtime we will use existing imperfect tools to compute the visual cue ( \emph{e.g.} \cite{poselet,pose_part} for pose estimation) before classifying it into one of the proxemes, and therefore the recognized proxeme may be erroneous. As a result of both uncertainties, for a detected, tracked and correctly-identified pair of individuals Alice $(i)$ and Bob $(j)$,
we can learn from training data representations of $P(A^{(v)}(i,j) \mid y^u)$: the probability of a relationship between $i$ and $j$ according to the $v$th relationship view given a detected instance of a proxeme from the $u$th dictionary. An interesting challenge we must address is that identities $i$ and $j$ will also be noisy, since they will be inferred from face recognition and other biometric cues. For example, if we cannot visually distinguish Bob ($j$) from Charlie ($k$) then a single cue $u$ can produce two separate probabilistic signals: $P(A^{(v)}(i,j) \mid y^u)=P(A^{(v)}(i,k) \mid y^u)$.


%\boldstart{Multi-view network regression}. One of our project goals is to establish a unified, data-driven framework for reconstructing multi-view network representations (affinity matrices $A^{(v)}$) from multiple noisy, heterogeneous visual sources. We refer to this problem as multi-source multi-view network estimation, and we will address it using an architecture comprised of $V$ trained \emph{oracles} $\Psi_{v}$ that each provide an estimate of one view $\hat{A}^{(v)}$ from all available vision-based descriptors $\bar{\vy}=[\vy^1,\vy^2, \cdots,\vy^S]$. That is, $\hat{A}^{(v)}=\Psi_{v}(\bar{\vy})$, with $\Psi_{v}$ learned from data according to the following general approach. Given collections of vision-based social cues $\{\bar{\vy}_{n}\}_{n=1}^{N}$ attributed to $N$ different unknown social network graphs, optionally supplemented by additional collections $\{\bar{\vy}_{n}\}_{n=1}^{M}$ attributed to $M$ graphs that are known (i.e., known
%affinity matrices $\{\bar{A}^{(v)}_{m}\}_{m=1}^{M}$, perhaps through non-visual metadata like that described in Section \ref{sec:sys}), we will investigate a family of objectives of the form
%\begin{equation}\label{eq:sensing}
%\{\Psi^{*}_{v}\}=\arg\!\!\!\!\!\!\!\!\min_{\{\Psi_{v}\},\{\hat{A}^{(v)}_l\}_{l=1}^{N+M}}\sum_{m=1}^{M}\mathcal{J}\left(\{\Psi_{v}\}, \{\bar{\vy}_m\}, \{\bar{A}^{(v)}_m\}\right)+\tau\left(\{\hat{A}^{(v)}_m\},\{\hat{A}^{(v)}_n\}\right)+\gamma\left(\{\Psi_{v}\}\right).
% \end{equation}
%The first term $\mathcal{J}$ in this expression is a loss term that gives preference to oracles that agree with the $M$ known graphs. For example, $\mathcal{J}(\{\Psi_{v}\}, \{\bar{\vy}_m\}, \{\bar{A}^{(v)}_m\})=\sum_{v=1}^{V}\|\Psi_{v}(\vy_m)-A^{(v)}_m\|^{2}$ would measure discrepancy from the known graphs in a least-square sense. To prevent over-fitting, the complexity of the oracles is restricted by a regularization term $\gamma()$, whose form depends on the choice of oracles, such as Gaussian process regression \cite{GPbook} or deep learning \cite{DLbook}. We will also explore modifying this regularization term to enforce compatibility between the oracles of different views. Two oracles predicting friendship and adversarialism for the same pair of nodes, for example, should be deemed incompatible. Finally, we include a third term $\tau()$ that regularizes the estimated affinity matrices according to some generic or environment-specific prior knowledge. For these, we will draw inspiration from the many existing statistical graph models~\cite{Goldenberg}.
%
%In this thread of our research, cross-view compatibility and within-view clustering are expected to play essential roles in the multi-view architecture. This distinguishes the proposed work from conventional regression machines, where outputs are mutually independent.


\boldstart{Multi-cue network estimation}. Assume we have detected proxemes in $N$ images or videos, in which not all pairs of social members are simultaneously observed together. To accommodate these ``missing links'', we define $Q(i,j,n)=1$ to indicate that individuals $i$ and $j$ co-occur in the $n$-th image or video, and $Q(i,j,n)=0$ otherwise. Consequently, $Q(i,j)\triangleq\prod_{n=1}^{N}Q^{(v)}(i,j,n)$ indicates whether the pair $(i, j)$ co-occurs at least once in the entire set.


A MAP estimate for the affinity $A^{(v)}(i,j)$ between individuals $i$ and $j$ for whom $Q (i,j)=1$ is
\begin{equation}
\{A^{(v)}(i,j)\}_{Q(i,j)=1}=\arg\!\!\!\!\!\min_{A^{(v')}(i,j)}\sum_{u=1}^{U}\sum_{n=1}^{N}Q(i,j,n)\log P(A^{(v')}(i,j)|y^u)+\gamma(\{A^{(v')}(i,j)\}),
\label{netestimate}
\end{equation}
where we assume independence among difference visual cues and different images or videos. The regularization term $\gamma()$ whose explicit format depends on the specific social network, is controls two important effects. First, it enforces compatibility between different nodes: friendship between nodes $i$ and $j$ and adversarialism between nodes $j$ and $k$, for example, suggest an adversarial prior between nodes $i$ and $k$ that should be reflected in this regularization. Second, it regularizes the estimated affinity matrices according to other environment-dependent prior knowledge about social networks, for which we will draw inspiration from existing statistical graph models such as~\cite{Goldenberg}. With $\gamma()$ properly defined, the problem (\ref{netestimate}) can be formulated as an optimization on a random field (over graph edges), and it can be tackled using standard random field algorithms. Our work in this direction will leverage the expertise of PI Li, who has a history of formulating and solving optimization problems on non-traditional domains~\cite{LiPAMI2012}.

The multi-cue network estimation framework is robust to noisy inputs: The evidence about the affinity between a particular pair is aggregated from proxemes using multiple cues and from multiple co-occurrences in the entire image or video set. Therefore, noisy input from a single visual cue and proxeme detection (\emph{e.g.}, noisy pose estimation and noisy pose-pair proxeme) on a single image or video will be overwhelmed by other reliable visual cues and proxemes which are correctly extracted from other images or videos.

%\begin{figure}[t!]
%\begin{center}
%\includegraphics[width=\columnwidth]{featurelearn}
%\end{center}
%\vspace{-0.25in} \caption{\captionsize
%Illustrations for the problem of multi-view network learning from multiple low-level visual clues and the framework of integrated socially-aware computer vision for understanding student netwrok. \label{fig:featurelearn}\afterfigspace}
%\end{figure}






%\boldstart{Reconstructing noise and missing data}. Even with identity recognition aside, the social information extracted from images and videos will be very noisy and incomplete. In many situations, images and videos will be of low quality; agents will exhibit significant pose variations and be occluded; tracking systems will become lost in clutter; and estimates of head pose, body pose, expression, etc. will be plagued by uncertainty. Consequently, missing and noisy links will be especially prevalent in visually-sensed social networks. As part of the proposed activity, we will build on successes in link prediction~\cite{Goldberg,Liben-Nowell,TaskarWAK03} and network completion~\cite{Clauset,Guimera,HannekeX09,KimL11}, by developing reconstruction tools that are better suited to highly-noisy and multi-view visually-sensed social networks.

\boldstart{Reconstructing missing links}. We have introduced a framework (\ref{netestimate}) to estimate the multi-view affinities between the pairs who co-occur at least once, but we must also develop tools for reasoning about members that do not co-occur and are missing links in the network. Meanwhile, due to other potential factors unaccounted in (\ref{netestimate}), estimated affinities may remain noisy.  As part of the proposed activity, we will build on successes in link prediction~\cite{Goldberg,Liben-Nowell,TaskarWAK03} and network completion~\cite{Clauset,Guimera,HannekeX09,KimL11}, by developing reconstruction tools that are better suited to multi-view social networks with highly noisy and missing links.

%To accommodate missing data, we will modify our representation for a social network graph of $K$ nodes by including a visibility matrix for each view. That is, $G\triangleq\{A^{(v)}, Q^{(v)}\} v=1,2,\cdots,V$, with $A^{(v)}$  the $K\times K$ affinity matrix for view $v$ and $Q^{(v)}$  the corresponding $K\times K$ visibility matrix for that view. If $Q^{(v)}(i,j)=1$, then $A^{(v)}(i,j)$ is the weight describing the tie or closeness between node $i$ and node $j$ estimated from the $v$th view; otherwise if $Q^{(v)}(i,j)=0$ then $A^{(v)}(i,j)$ is a missing number indicating the lack of information in this view. Our objective is to complete the missing links ($Q^{(v)}(i,j)=0$) by estimating the proper weights for these missing links.

%In the case that the views directly correspond to low-level visual cues, we may imagine that the ties between the pairs of members should not vary among different views due to different sensing modalities, and therefore there exist a unique community structure underlying all views. A primary objective in this case, is that how we may discover the community (clustering) effect from this partially observed multi-view network, together with filling the missing links with a proper weight. We refer to this primary task as network reconstruction.

The key observation is that structure across views can be used to transfer information from one view to the other view, effectively filling holes or filtering noise by borrowing information from other views. This will succeed as long as errors are incoherent across views\comment{, which is a reasonable expectation in practice}. To operationalize this, we let each node $i$ in the graph be uniquely identified with a point $\vx_i$ in a Euclidean space of some dimension, where the distance between each pair of points $(i,j)$ in this space can be interpreted as form of ``view-invariant" dissimilarity between the two nodes. Furthermore, we imagine that every view-specific affinity $A^{(v)}$ can be obtained by a simple global linear transform of the view-invariant Euclidean distance. This model is supported by the following theorem, based on results from multi-dimensional scaling~\cite{CoxMDS} (proof omitted due to space constraints), implying that any graph affinity can be analytically transformed to Euclidean distances between points.

\begin{quote}
\textbf{Theorem}. \textit{If $A$ is a symmetric affinity matrix with all zeros on the diagonal and positive numbers everywhere else, there exists a constant $c$ such that $(\frac{1}{A(i,j)}+c)^{\frac{1}{2}}$ is the Euclidean distance between point $i$ (representing node $i$) and point $j$ (representing node $j$) in an Euclidean space, where $c\geq\lambda$, the smallest eigenvalue of $\Lambda=H\Gamma H$, $H=\mathbf{I}-\frac{\mathbf{1}\mathbf{1}^T}{K}$, and $\Gamma(i,j)=-\frac{1}{2A(i,j)}$.} 
\end{quote}

The theorem guarantees that each node can be uniquely identified with a point in a Euclidean space, and then one possible way for the Euclidean-embedded nodes $\vx_i$ and the multi-view network $G$ to be related is to let $((\vx_i-\vx_j)^{T}\Sigma^{(v)}(\vx_i-\vx_j)-c^{(v)})^{-1}=A^{(v)}(i,j)+\epsilon^{(v)}_{ij}$, where $\Sigma^{(v)}$ is a symmetric semi-positive definite matrix specific to the $v$th view, and $\epsilon$ is a residual. By doing so, different views are unified, and any network priors or regularizations across views are straightforward to be transferred through the embedded points $\vx_i$. 

This model we propose differs from existing analyses of embedding~\cite{Hoff01latentspace,Hancocklatent}, multi-view networks \cite{AiroldiBFX08,Kim12}, and network completion~\cite{Clauset,Guimera,HannekeX09,KimL11}, because it uses a latent Euclidean embedding to \emph{simultaneously} consider missing data and multiple views. It promises more effective use of structure that exists across distinct views in a network, something that we view as being very important to the success of vision-based network reconstruction. 

%A unified community clustering effect, as the social network prior, may consequently  be modeled in the Euclidean space as well, for example, via
%\begin{equation}\label{eq:kmeans}
%Z=\arg\min_{D,\hat{Z}}\|X-D\hat{Z}\|^{2}_{2}, \textup{s.t.} \hat{Z}^{T}\mathbf{1}=\mathbf{1},
% \end{equation}
%where $X=[\vx_1,\vx_2,\cdots,\vx_K]$, each column of $D$ represents the center of a cluster, and $Z, \hat{Z}$ are a binary matrices by which we assign a node to a cluster among the communities of interest given by $D$. Upon learning the overall model incorporating the essential components in (\ref{eq:embed})(\ref{eq:kmeans}). It is straightforward to reconstruct the noisy and the missing affinities through transforms of Euclidean distances, and to investigate the underlying community structure invariant of views.

\subsection{Closing the Loop: Joint coarsening, filtering, and relationship detection}
\label{sec:closeloop}

A longer term goal of our research is to allow synergistic collaboration between visual recognition processes and social reconstructive processes. We have argued that visual recognition provides information about an underlying social network, but the converse is also true. As shown by PI Zickler~\cite{Stone2008,Stone2010} and others, social network information can serve as context to improve recognition. We imagine a future in which these two processes work together. When uncertainty in a face recognition system leads to low confidence in identities, the uncertainty propagates to the extracted social cues $\vy$ and therefore to the inferred social network graph $G$. However, by reconstructing and denoising the multi-view graph as proposed above, we can improve our estimate of the underlying social network, and then carry this information back to the image data, use the the improved social network as context to correct  errors and improve recognition models.
